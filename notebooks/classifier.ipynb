{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b69925-dfd8-414a-88fc-485aac8b236f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raven/u/noka/VAEEG\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClipDataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mold_modelA\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAEEG, re_parameterize\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n",
      "File \u001b[0;32m/raven/u/noka/VAEEG/src/model/opts/dataset.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClipDataset\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys \n",
    "sys.path.insert(0, '/raven/u/noka/VAEEG') \n",
    "from src.model.opts.dataset import ClipDataset\n",
    "from src.model.net.modelA import VAEEG, re_parameterize\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d12e70e-e158-4e70-841a-f4b43815ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model: nn.Module, ckpt_file: str):\n",
    "    \"\"\"\n",
    "    Loads a checkpoint saved from single- or multi-GPU training into a model\n",
    "    running on a single GPU or CPU. Returns any auxiliary info found.\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    ckpt = torch.load(ckpt_file, map_location=device)\n",
    "    sd = ckpt[\"model\"]\n",
    "\n",
    "    # Remove \"module.\", if saved under DataParallel/DDP\"\n",
    "    if next(iter(sd)).startswith(\"module.\"):\n",
    "        sd = {k[len(\"module.\"):]: v for k, v in sd.items()}\n",
    "    model.load_state_dict(sd)\n",
    "    model.to(device)\n",
    "    \n",
    "    return device\n",
    "def init_model(in_channels, z_dim, deterministic, ckpt_file, negative_slope=0.2, decoder_last_lstm=False): \n",
    "    model = VAEEG(in_channels=in_channels,\n",
    "                    z_dim=z_dim,\n",
    "                    negative_slope=negative_slope,\n",
    "                    decoder_last_lstm=decoder_last_lstm,\n",
    "                    deterministic=deterministic)\n",
    "    device = load_model(model, ckpt_file=ckpt_file)\n",
    "    return model, device\n",
    "def init_dl(data_root, band, batch_size=1024, num_workers=1, shuffle=False): \n",
    "    ds = ClipDataset(\n",
    "        data_dir=data_root,\n",
    "        band_name=band,\n",
    "        clip_len=256\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return loader\n",
    "def get_latent(model, loader, device, z_dim):\n",
    "    model.eval()\n",
    "    num_samples = len(loader.dataset)\n",
    "    z_arr = np.zeros((num_samples, z_dim), dtype=np.float32)  \n",
    "    idx = 0\n",
    "    encoder = model.module.encoder if hasattr(model, 'module') else model.encoder\n",
    "    # Get the deterministic setting from the model\n",
    "    deterministic = model.module.deterministic if hasattr(model, 'module') else model.deterministic\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(device)\n",
    "            mu, log_var = encoder(x)\n",
    "            if deterministic:\n",
    "                z_batch = mu  # In deterministic mode, log_var is None, so just use mu\n",
    "            else:\n",
    "                z_batch = re_parameterize(mu, log_var, deterministic=deterministic)\n",
    "            bs = z_batch.size(0)\n",
    "            z_arr[idx:idx + bs, :] = z_batch.cpu().numpy()\n",
    "            idx += bs\n",
    "    return z_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db623aa7-67bc-44c1-b0d1-b71763694903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for latents\n",
    "ae_latents = {} \n",
    "vae_latents = {}\n",
    "pca_latents = {}\n",
    "pca_train = {}\n",
    "pca_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321be84f-fc01-4459-86b8-22b586d882c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "bands = [\"delta\", \"theta\", \"alpha\", \"low_beta\", \"high_beta\"]\n",
    "z_dim = 32\n",
    "epoch = 37\n",
    "in_channels=1\n",
    "seed = 42 \n",
    "deterministic = False\n",
    "if deterministic: \n",
    "    ckpt_root = \"/raven/u/noka/VAEEG/models_new/vanilla\"\n",
    "else: \n",
    "    ckpt_root = \"/raven/u/noka/VAEEG/models_new/variational\"\n",
    "data_dir = \"/ptmp/noka/new_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8329edc-3c8e-43d6-8ecf-74087ca4427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:00<00:00, 24.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for PCA fitting\n",
    "rng_test = np.random.RandomState(seed)\n",
    "starts_test = rng_test.randint(0, 1280 - 256 + 1, size=288182)\n",
    "rng_train = np.random.RandomState(seed)\n",
    "starts_train = rng_train.randint(0, 1280 - 256 + 1, size=2575060)\n",
    "for band in tqdm(bands): \n",
    "    band_train = np.load(os.path.join(data_dir, \"train\", f\"{band}.npy\"))\n",
    "    band_test = np.load(os.path.join(data_dir, \"test\", f\"{band}.npy\"))\n",
    "    orig_train = np.zeros((band_train.shape[0], 256), dtype=band_train.dtype)\n",
    "    orig_test = np.zeros((band_test.shape[0], 256), dtype=band_test.dtype)\n",
    "    for i in range(band_train.shape[0]):\n",
    "        orig_train[i] = band_train[i, starts_train[i]:starts_train[i] + 256]\n",
    "    for i in range(band_test.shape[0]):\n",
    "        orig_test[i] = band_test[i, starts_test[i]:starts_test[i] + 256]\n",
    "    pca_train[band] = orig_train\n",
    "    pca_test[band] = orig_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529a7dda-17fe-4650-a219-b33bc3aaf78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get AE and VAE latents\n",
    "for band in tqdm(bands):\n",
    "    ckpt_file = os.path.join(ckpt_root, band, f\"z{z_dim}\", f\"ckpt_epoch_{epoch}.ckpt\")\n",
    "    model, device = init_model(in_channels=in_channels, z_dim=z_dim, deterministic=deterministic, ckpt_file=ckpt_file)\n",
    "    loader = init_dl(os.path.join(data_dir, \"test\"), band)\n",
    "    latent = get_latent(model=model, loader=loader, device=device, z_dim=z_dim)\n",
    "    if deterministic: \n",
    "        ae_latents[band] = latent\n",
    "    else: \n",
    "        vae_latents[band] = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a94295-cc3b-46ed-9d46-bc95335c0c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio sum: 0.99999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio sum: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio sum: 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:02<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio sum: 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio sum: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get PCA latents\n",
    "for band in tqdm(bands):\n",
    "    data_train = pca_train[band]   \n",
    "    pca = PCA(n_components=50, random_state=42)\n",
    "    pca.fit(data_train)\n",
    "    print(\"Explained variance ratio sum:\", np.sum(pca.explained_variance_ratio_))\n",
    "    data_test = pca_test[band]     \n",
    "    latents = pca.transform(data_test)\n",
    "    pca_latents[band] = latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa29aab9-b6ba-47a8-9308-89bf187559e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_vae = {}\n",
    "lr_ae = {}\n",
    "lr_pca = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbc616f7-4bf9-4870-910b-f9badf570d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_vae = {}\n",
    "knn_ae = {}\n",
    "knn_pca = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a47b90-327b-4cf7-ae0e-559d73d3422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural scatter ratio (trace(S_B)/trace(S_W)): 0.0024\n"
     ]
    }
   ],
   "source": [
    "X = vae_latents[\"alpha\"]\n",
    "y = np.load(\"/ptmp/noka/labels/test.npy\")\n",
    "\n",
    "classes = np.unique(y)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "mu = np.mean(X, axis=0)\n",
    "\n",
    "S_W = np.zeros((n_features, n_features))\n",
    "S_B = np.zeros((n_features, n_features))\n",
    "\n",
    "for c in classes:\n",
    "    X_c = X[y == c]\n",
    "    mu_c = np.mean(X_c, axis=0)\n",
    "    n_c = X_c.shape[0]\n",
    "\n",
    "    # Within-class scatter\n",
    "    S_W += (X_c - mu_c).T @ (X_c - mu_c)\n",
    "\n",
    "    # Between-class scatter\n",
    "    mean_diff = (mu_c - mu).reshape(-1, 1)\n",
    "    S_B += n_c * (mean_diff @ mean_diff.T)\n",
    "\n",
    "# Natural scatter ratio\n",
    "scatter_ratio = np.trace(S_B) / np.trace(S_W)\n",
    "print(f\"Natural scatter ratio (trace(S_B)/trace(S_W)): {scatter_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f4f09b6-913a-4b88-81fe-a457d76996a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851  |  ROC-AUC: 0.727\n",
      "Confusion matrix:\n",
      " [[61289   485]\n",
      " [10229    43]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "X = vae_latents[\"alpha\"]        \n",
    "y = np.load(\"/ptmp/noka/labels/test.npy\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1, priors=[0.9, 0.1])  \n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lda.predict(X_test)                \n",
    "y_proba = lda.predict_proba(X_test)[:, 1]   \n",
    "\n",
    "# --- Basic metrics ---\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "auc  = roc_auc_score(y_test, y_proba)\n",
    "cm   = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}  |  ROC-AUC: {auc:.3f}\")\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "728f3bde-2233-44d4-adbb-f9d651468eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(\"/ptmp/noka/labels/test.npy\")\n",
    "for band in bands: \n",
    "    X = ae_latents[band]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    # --- Logistic Regression ---\n",
    "    logreg = LogisticRegression(\n",
    "        random_state=42, \n",
    "        class_weight=\"balanced\", \n",
    "        solver=\"saga\", \n",
    "        max_iter=200,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and probabilities\n",
    "    y_pred  = logreg.predict(X_test)\n",
    "    y_proba = logreg.predict_proba(X_test)[:, 1] \n",
    "    auc  = roc_auc_score(y_test, y_proba)\n",
    "    lr_ae[band] = auc, y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69881e0c-a53b-4eb5-b61b-3e821c00e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446073795703099"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ae[\"theta\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14a40442-607e-48b4-a992-4115eba56b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DeLong Test ===\n",
      "Samples: total=72046, pos=10272, neg=61774\n",
      "Tie rate: A=0.005, B=0.196\n",
      "Step 1) Attempt standard DeLong.\n",
      "[delong] z = -36.077465, p = 5.118e-285\n",
      "z-score  : -36.0775, p-value = 5.118e-285 ***\n",
      "=== DeLong Test ===\n",
      "Samples: total=72046, pos=10272, neg=61774\n",
      "Tie rate: A=0.004, B=0.145\n",
      "Step 1) Attempt standard DeLong.\n",
      "[delong] z = -57.212027, p = 0.000e+00\n",
      "z-score  : -57.2120, p-value = 0.000e+00 ***\n",
      "=== DeLong Test ===\n",
      "Samples: total=72046, pos=10272, neg=61774\n",
      "Tie rate: A=0.004, B=0.138\n",
      "Step 1) Attempt standard DeLong.\n",
      "[delong] z = -52.771932, p = 0.000e+00\n",
      "z-score  : -52.7719, p-value = 0.000e+00 ***\n",
      "=== DeLong Test ===\n",
      "Samples: total=72046, pos=10272, neg=61774\n",
      "Tie rate: A=0.008, B=0.183\n",
      "Step 1) Attempt standard DeLong.\n",
      "[delong] z = -47.872723, p = 0.000e+00\n",
      "z-score  : -47.8727, p-value = 0.000e+00 ***\n",
      "=== DeLong Test ===\n",
      "Samples: total=72046, pos=10272, neg=61774\n",
      "Tie rate: A=0.007, B=0.240\n",
      "Step 1) Attempt standard DeLong.\n",
      "[delong] z = -39.169505, p = 0.000e+00\n",
      "z-score  : -39.1695, p-value = 0.000e+00 ***\n"
     ]
    }
   ],
   "source": [
    "from MLstatkit import Delong_test\n",
    "\n",
    "for band in bands: \n",
    "    z, p, ci_A, ci_B, auc_A, auc_B, info = Delong_test(\n",
    "        y_test, lr_auc_ae[band][1], lr_auc_pca[band][1],\n",
    "        alpha=0.95, return_ci=True, return_auc=True, verbose=1\n",
    "    )\n",
    "\n",
    "    def stars_from_p(p):\n",
    "        if p < 0.001:\n",
    "            return \"***\"\n",
    "        elif p < 0.01:\n",
    "            return \"**\"\n",
    "        elif p < 0.05:\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    print(f\"z-score  : {z:.4f}, p-value = {p:.3e} {stars_from_p(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a10e505-5ce3-416a-8406-ccc908499ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "idx_seiz = np.where(y == 1)[0]\n",
    "idx_bkgd = np.where(y == 0)[0]\n",
    "n_seiz   = len(idx_seiz)\n",
    "\n",
    "idx_bkgd_down = rng.choice(idx_bkgd, size=n_seiz, replace=False)\n",
    "idx_bal = np.concatenate([idx_seiz, idx_bkgd_down])\n",
    "rng.shuffle(idx_bal)\n",
    "for band in bands:\n",
    "    X = raws[band]\n",
    "    X_bal = X[idx_bal]\n",
    "    y_bal = y[idx_bal]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_bal, y_bal, test_size=0.25, random_state=42, stratify=y_bal\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    k = 287  \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = knn.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    knn_raw[band] = (auc, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b65c4b3e-e980-4165-a6da-59eed37c8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: 0.710\n",
      "theta: 0.747\n",
      "alpha: 0.740\n",
      "low_beta: 0.718\n",
      "high_beta: 0.674\n"
     ]
    }
   ],
   "source": [
    "for band, (auc, y_proba) in knn_pca.items():\n",
    "    print(f\"{band}: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adec8550-49a3-466c-8451-cecec0172e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw\n",
    "raws = {}\n",
    "for band in bands: \n",
    "    raw = np.load(os.path.join(data_dir, f\"test/{band}.npy\"))\n",
    "    raws[band] = raw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bdecf04-7292-4b7b-b4a0-14ba7b460f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20544"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(knn_vae[band][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53a10777-b609-49c4-b59a-af578fd7b46d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "true, prob_A, prob_B must have the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMLstatkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Delong_test\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m band \u001b[38;5;129;01min\u001b[39;00m bands: \n\u001b[0;32m----> 4\u001b[0m     z, p, ci_A, ci_B, auc_A, auc_B, info \u001b[38;5;241m=\u001b[39m \u001b[43mDelong_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_auc_vae\u001b[49m\u001b[43m[\u001b[49m\u001b[43mband\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknn_vae\u001b[49m\u001b[43m[\u001b[49m\u001b[43mband\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_ci\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_auc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstars_from_p\u001b[39m(p):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.001\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/MLstatkit/delong.py:87\u001b[0m, in \u001b[0;36mDelong_test\u001b[0;34m(true, prob_A, prob_B, alpha, return_ci, return_auc, n_boot, random_state, verbose, progress_every)\u001b[0m\n\u001b[1;32m     84\u001b[0m pB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(prob_B, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m pA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m pA\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m pB\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue, prob_A, prob_B must have the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m pA\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m pB\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs must be 1-D arrays.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: true, prob_A, prob_B must have the same length."
     ]
    }
   ],
   "source": [
    "from MLstatkit import Delong_test\n",
    "\n",
    "for band in bands: \n",
    "    z, p, ci_A, ci_B, auc_A, auc_B, info = Delong_test(\n",
    "        y_test, lr_auc_vae[band][1][idx_bal], knn_vae[band][1],\n",
    "        alpha=0.95, return_ci=True, return_auc=True, verbose=1\n",
    "    )\n",
    "\n",
    "    def stars_from_p(p):\n",
    "        if p < 0.001:\n",
    "            return \"***\"\n",
    "        elif p < 0.01:\n",
    "            return \"**\"\n",
    "        elif p < 0.05:\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    print(f\"z-score  : {z:.4f}, p-value = {p:.3e} {stars_from_p(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa3ae7-81ba-460b-96cd-5c7fe9f4f742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
